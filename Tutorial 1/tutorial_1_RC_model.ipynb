{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb151b74-1ec9-47a2-a86f-66b63df52718",
   "metadata": {},
   "source": [
    "# **Tutorial 1: Modelling Heat Transfer in Buildings**\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial, we estimate data-driven heat transfer models for a building envelope. We use real-world measurement data from an occupied, semi-detached house in the UK [1], which was retrofit in Spring/Summer 2016 and occupied in September 2016. The data set is publicly available [here](https://discovery.ucl.ac.uk/id/eprint/10087216/) and comprises two 5-day periods of measurements at a 10-minute resolution.\n",
    "\n",
    "By the end of this tutorial, you should be able to:\n",
    "- Process and interpret building measurement data.\n",
    "- Formulate data-driven (grey- and black-box) models for building heat transfer.\n",
    "- Compare and validate different modelling approaches using good-of-fit and statistical metrics.\n",
    "\n",
    "[1] Hollick, F; Wingfield, J; (2018) Two periods of in-situ measurements from an occupied, semi-detached house in the UK [Dataset]. 10.14324/000.ds.10087216."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b00e6f2-fcb1-4c90-b7a5-19b9e565cb7a",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "Load the necessary Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d54e8b2-ad5a-4120-9832-7a43d2270575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.constrained_layout.use'] = True\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "plt.rcParams['figure.figsize'] = (10,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56d5f8-37e7-4493-99e3-cac3e64ef6ac",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "We first load and visualize the data. First, set up the ```data_path``` variable to the correct file location and load the data set. The data set spans two 5-day periods. The data from the first period (November 2016) is considered first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c9ba4f-4900-4303-9fdf-9bfb72adcf44",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\ucbva19\\\\Git projects\\\\BENV0092\\\\data\\\\10mins_solpap_2016.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#%% Load measurement data\u001b[39;00m\n\u001b[0;32m      3\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mucbva19\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mGit projects\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mBENV0092\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m10mins_solpap_2016.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m data\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\conda_envs\\benv0092\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\conda_envs\\benv0092\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\conda_envs\\benv0092\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\conda_envs\\benv0092\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\conda_envs\\benv0092\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ucbva19\\\\Git projects\\\\BENV0092\\\\data\\\\10mins_solpap_2016.csv'"
     ]
    }
   ],
   "source": [
    "#%% Load measurement data\n",
    "\n",
    "data_path = 'C:\\\\Users\\\\ucbva19\\\\Git projects\\\\BENV0092\\\\data'\n",
    "data = pd.read_csv(f'{data_path}\\\\10mins_solpap_2016.csv', index_col = 0)\n",
    "data.index = pd.to_datetime(data.index, format=\"%d/%m/%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1be448-3774-4c4b-83e3-bc54dc0109af",
   "metadata": {},
   "source": [
    "### Preliminary analysis\n",
    "\n",
    "The first task is to familiarize ourselves with the data and assess its quality. To familiarize with the data, we can generate plots, provide summary statistics, and estimate correlations/ autocorrelations.\n",
    "\n",
    "**Discussion**:\n",
    "- Interpret parameters and estimate some summary statistics.\n",
    "- Describe some salient characteristics of the ```P_tot (W)``` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c83a1c9-4d1b-4437-a206-4ed01b3e44c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())\n",
    "print(f'Percentage of missing observations: {100*data.isna().sum()/len(data)}')\n",
    "\n",
    "# Visualization \n",
    "fig, ax = plt.subplots(figsize=(10,8), nrows = 3, sharex = True)\n",
    "\n",
    "data['P_tot (W)'].plot(ax=ax[0])\n",
    "data[['T_External (degC)', 'T_Average (degC)', 'T_Thermostat (degC)', 'T_Bed1 (degC)', 'T_Living (degC)']].plot(ax=ax[1])\n",
    "data['Solar (W/m2)'].plot(ax = ax[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d287fd0-0c84-4f4c-a5cf-e9a6a353af9a",
   "metadata": {},
   "source": [
    "### Dealing with missing data\n",
    "\n",
    "Some variables contain missing data. A good practice is to visually examine the missing data and then pick an appropriate imputation method. Considering that we are dealing with 10-minute time series data, a simple linear interpolation seems sensible. \n",
    "\n",
    "**Discussion**:\n",
    "- Consider the most common imputation method, i.e., replacing with the mean value. Is this a good approach here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64209204-f415-44dd-8712-74585e261977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing data with linear interpolation\n",
    "data = data.interpolate('linear')\n",
    "assert(data.isna().all().sum() == 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a23c5d-2e9a-4269-a959-ee7734ae2ef3",
   "metadata": {},
   "source": [
    "## Modelling heat transfer\n",
    "\n",
    "We will formulate different data-driven models for the envelope heat transfer model. The following assumptions are in place:\n",
    "- We consider a single-zone model and use the average room temperature, ```T_Average (degC)```, as a proxy.\n",
    "- We consider a 10-minute discretization step, i.e., $dt=1/6$, which is the same as the data granularity.\n",
    "- We use the total power, ```P_tot (W)```, as a proxy for the net heat injection, which is a simplification. Ideally, we would like to include potential losses. This means that we need to be careful with the physical interpretation of the estimated parameters.\n",
    "\n",
    "To streamline the code, we introduce auxiliary variables and set up parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bb0816-287f-4942-a758-911284a7ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead T_in values (target variable)\n",
    "data['T_Average_lead_1'] = data['T_Average (degC)'].shift(-1)\n",
    "data['T_diff'] = data['T_External (degC)'] - data['T_Average (degC)']\n",
    "\n",
    "# Drop NaNs created from the shift operator\n",
    "data = data.dropna()\n",
    "\n",
    "# discretization step at 10 minutes\n",
    "dt_h = 1/6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55ae144a-3a45-4893-b0cf-9d93f565fc97",
   "metadata": {},
   "source": [
    "### Deriving the $RC$ model\n",
    "\n",
    "We consider a simple $1R-1C$ model to approximate the heat transfer dynamical model of a single-zone dwelling.:\n",
    "\n",
    "- $R_{\\text{th}}$ = thermal resistance (째C/kW)  \n",
    "- $C_{\\text{th}}$ = thermal capacitance (kWh/째C)\n",
    "- $\\tau = R_{\\text{th}} C_{\\text{th}}$ = time constant\n",
    "\n",
    "The continuous-time energy balance is given by\n",
    "\n",
    "<center>$ C_{\\text{th}} \\frac{dT}{dt} = \\frac{T_\\text{ext} - T}{R_{\\text{th}}} + H_\\text{heat} + g H_\\text{solar}$,</center>\n",
    "\n",
    "\n",
    "where $T$ is the average indoor temperature (째C), $T_\\text{ext}$ is the external temperature (째C), and $H_\\text{heat}$ is the sensible heat injection in the node (kW), $H_\\text{solar}$ is the solar radiation, and $g$ is the (unknown) solar gain factor.\n",
    "\n",
    "Equivalently, we can write \n",
    "<center>$ \\frac{dT}{dt} =\n",
    "\\frac{1}{\\tau}(T_\\text{ext} - T)\n",
    "+ \\frac{1}{C_{\\text{th}}}H_{\\text{heat}} + \\frac{g}{C_{\\text{th}}}H_{\\text{solar}}$.</center>\n",
    "\n",
    "Using forward Euler discretization, we get\n",
    "<center>\n",
    "$\n",
    "T_{k+1}\n",
    "=\n",
    "T_k\n",
    "+ \\Delta t \\frac{1}{\\tau}(T_{\\text{ext},k} - T_k)\n",
    "+ \\Delta t \\frac{1}{C_{\\text{th}}} H_{\\text{heat},k} + \\Delta t \\frac{g}{C_{\\text{th}}} H_{\\text{solar},k},\n",
    "$    \n",
    "</center>\n",
    "\n",
    "\n",
    "where $k$ is the time step index. For convenience, we define the **discrete coefficients**:\n",
    "\n",
    "<center>\n",
    "$\n",
    "\\alpha_1 = \\frac{\\Delta t}{\\tau}, \\qquad\n",
    "\\alpha_2 = \\frac{\\Delta t}{C_{\\text{th}}}, \\qquad,\n",
    "\\alpha_3 = \\frac{\\Delta t g}{C_{\\text{th}}}.\n",
    "$    \n",
    "</center>\n",
    "\n",
    "The final discrete $RC$ model is given by\n",
    "\n",
    "<center>\n",
    "$\n",
    "T_{k+1} = T_k + \\alpha_1 (T_{\\text{out},k} - T_k)\n",
    "+ \\alpha_2 H_{\\text{heat},k} + \\alpha_3 H_{\\text{solar},k}.$\n",
    "</center>\n",
    "\n",
    "\n",
    "### $RC$ parameter estimation\n",
    "\n",
    "Next, we estimate the parameters of the $RC$ model, or, equivalently, coefficients $\\alpha_{1,2,3}$. Throughout, we use $\\hat{\\cdot}$ to denote parameters estimated (i.e., learned) from data. First, for the $k$th observation, we define the loss function\n",
    "\n",
    "<center>\n",
    "$\\ell(\\hat{T}_k, T_{k})=(\\hat{T}_k-T_{k})^2 = \\bigl(T_k + \\alpha_1(T_{\\text{out},k} - T_k)\n",
    "+ \\alpha_2 H_{\\text{heat},k} + \\alpha_3 H_{\\text{solar},k} - T_{k+1}\\bigr)^2$,\n",
    "</center> \n",
    "\n",
    "which represents the mean squared error (MSE) between predicted temperature $\\hat{T}$ and actual temperature $T$.\n",
    "To estimate the parameters, we minimize the empirical mean squared error over the training data set which contains $N$ observations, \n",
    "given by\n",
    "\n",
    "<center>\n",
    "$\\min_{\\alpha_{1,2,3}} \\sum_{k=1}^{N-1} \\ell(\\hat{T}_k, T_{k})$,    \n",
    "</center>\n",
    " \n",
    "which defines a constrained regression problem.\n",
    "\n",
    "**Excercise**: Your task is to solve the constrained optimization problem described above and return the $RC$ parameters. \n",
    "\n",
    "*Hint*: You can use the ```cvxpy``` library to formulate and solve a constrained optimization problem. The ```lsq_linear``` function can also be used to solve a constrained linear least squares problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582d7e48-f5e2-4d8b-88a4-ee1de96e0bb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%% Find parameters for lumped RC model\n",
    "\n",
    "Y = data['T_Average_lead_1']\n",
    "X = data[['T_diff', 'P_tot (W)', 'Solar (W/m2)', 'T_Average (degC)']]\n",
    "\n",
    "# Solve a constrained least-squares optimization problem to estimate RC parameters\n",
    "\n",
    "# Estimate in-sample Root Mean Squared Error\n",
    "print('In-sample RMSE')\n",
    "\n",
    "# Return parameters tau, C, R, g\n",
    "print('RC parameters')\n",
    "\n",
    "# Add a visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b0da87-85ec-4251-8c95-c34c1dfb2339",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "\n",
    "We now model the heat transfer as an (unconstrained) linear regression given by $f(x;\\theta) = \\theta^\\top x$, where $x$ concats all the features used (```['T_diff', 'P_tot (W)', 'Solar (W/m2)', 'T_Average (degC)']```) and $\\theta$ are the coefficients. To train the linear regression (i.e., to learn parameters $\\theta$) we need to solve\n",
    "\n",
    "<center>\n",
    "$\\min_{\\theta} \\sum_{k=1}^{N-1} \\ell(f(x;\\theta), T_{k})$,    \n",
    "</center>\n",
    "\n",
    "which is a standard least squares regression.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab178e0-452a-424d-bc76-efe500f162e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine feature vector\n",
    "Y = data['T_Average_lead_1']\n",
    "X = data[['T_diff', 'P_tot (W)', 'Solar (W/m2)', 'T_Average (degC)']]\n",
    "\n",
    "# Fit a linear regression model\n",
    "\n",
    "# Solve a constrained least-squares optimization problem to estimate RC parameters\n",
    "\n",
    "# Estimate in-sample Root Mean Squared Error\n",
    "print('In-sample RMSE')\n",
    "\n",
    "# Return parameters tau, C, R, g\n",
    "print('RC parameters')\n",
    "\n",
    "# Add a visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed965fcd-70aa-4fa1-9f82-928324e3c533",
   "metadata": {},
   "source": [
    "**Discussion**:\n",
    "- Which model has the lowest RMSE? Could you have guessed it beforehand?\n",
    "- Try to interpret RC parameters from unconstrained linear regression model. What happens? Do the values make sense?\n",
    "\n",
    "**Additional exercises**:\n",
    "- Estimate $R^2$ and other goodness-of-fit measures.\n",
    "- Fit a nonlinear machine learning model, e.g., random forecasts, gradient boosting.\n",
    "- Add more features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29893129-6220-4e5e-8481-d46a9ada7f05",
   "metadata": {},
   "source": [
    "## Repeating the experiment using June 2017 data\n",
    "\n",
    "Previous experiment used data from November 2016. We repeat the experiment using measurement data from June 2017. \n",
    "\n",
    "**Discussion:**\n",
    "- What do you observe? How are the estimated parameters affected? Is the fit better or worse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc61eb90-8108-441f-a3be-d3e9fe6d8ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Load measurement data from 2017\n",
    "data_17 = pd.read_csv(f'{data_path}\\\\10mins_solpap_2017.csv', index_col = 0)\n",
    "data_17.index = pd.to_datetime(data_17.index, format=\"%d/%m/%Y %H:%M\")\n",
    "\n",
    "# Fill missing data with linear interpolation\n",
    "data_17 = data_17.interpolate('linear')\n",
    "assert(data_17.isna().all().sum() == 0)\n",
    "\n",
    "# Lead T_in values (target variable)\n",
    "data_17['T_Average_lead_1'] = data_17['T_Average (degC)'].shift(-1)\n",
    "data_17['T_diff'] = data_17['T_External (degC)'] - data_17['T_Average (degC)']\n",
    "\n",
    "# Drop NaNs created from the shift operator\n",
    "data_17 = data_17.dropna()\n",
    "\n",
    "# Set discretization step to 10 minutes\n",
    "dt_h = 1/6\n",
    "\n",
    "# Fill missing data with linear interpolation\n",
    "data_17 = data_17.interpolate('linear')\n",
    "assert(data_17.isna().all().sum() == 0)\n",
    "\n",
    "# Visualization \n",
    "fig, ax = plt.subplots(figsize=(10,8), nrows = 3, sharex = True)\n",
    "\n",
    "data_17['P_tot (W)'].plot(ax=ax[0])\n",
    "data_17[['T_External (degC)', 'T_Average (degC)', 'T_Thermostat (degC)', 'T_Bed1 (degC)', 'T_Living (degC)']].plot(ax=ax[1])\n",
    "data_17['Solar (W/m2)'].plot(ax = ax[2])\n",
    "plt.show()\n",
    "\n",
    "###########%% Find parameters for lumped RC model\n",
    "\n",
    "Y = data_17['T_Average_lead_1']\n",
    "X = data_17[['T_diff', 'P_tot (W)', 'Solar (W/m2)', 'T_Average (degC)']]\n",
    "\n",
    "# Estimate in-sample Root Mean Squared Error\n",
    "print('In-sample RMSE')\n",
    "\n",
    "# Return parameters tau, C, R, g\n",
    "print('RC parameters')\n",
    "\n",
    "# Add a visualization\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
